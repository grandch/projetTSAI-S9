{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: give limits to random\n",
    "def spatialAug1(sentinel1):\n",
    "    vv = np.array(sentinel1.read(1))\n",
    "    vh = np.array(sentinel1.read(2))\n",
    "\n",
    "    i1 = np.random.randint(low=0, high=vv.shape[0]-2, size=None)\n",
    "    i2 = np.random.randint(low=i1, high=vv.shape[0]-1, size=None)\n",
    "    j1 = np.random.randint(low=0, high=vv.shape[1]-2, size=None)\n",
    "    j2 = np.random.randint(low=j1, high=vv.shape[1]-1, size=None)\n",
    "\n",
    "    vv_croped = vv[i1:i2, j1:j2]\n",
    "    vh_croped = vh[i1:i2, j1:j2]\n",
    "\n",
    "    vv_resized = cv2.resize(vv_croped, dsize=(512, 512))\n",
    "    vh_resized = cv2.resize(vh_croped, dsize=(512, 512))\n",
    "    fill = np.zeros((512,512))\n",
    "\n",
    "    return np.stack((vv_resized, vh_resized, fill), axis=2)\n",
    "\n",
    "def spatialAug2(sentinel2):\n",
    "    r = np.array(sentinel2.read(3))\n",
    "    g = np.array(sentinel2.read(2))\n",
    "    b = np.array(sentinel2.read(1))\n",
    "\n",
    "    i1 = np.random.randint(low=0, high=r.shape[0]-2, size=None)\n",
    "    i2 = np.random.randint(low=i1, high=r.shape[0]-1, size=None)\n",
    "    j1 = np.random.randint(low=0, high=r.shape[1]-2, size=None)\n",
    "    j2 = np.random.randint(low=j1, high=r.shape[1]-1, size=None)\n",
    "\n",
    "    r_croped = r[i1:i2, j1:j2]\n",
    "    g_croped = g[i1:i2, j1:j2]\n",
    "    b_croped = b[i1:i2, j1:j2]\n",
    "\n",
    "    r_resized = cv2.resize(r_croped, dsize=(512, 512))\n",
    "    g_resized = cv2.resize(g_croped, dsize=(512, 512))\n",
    "    b_resized = cv2.resize(b_croped, dsize=(512, 512))\n",
    "\n",
    "    return np.stack((r_resized, g_resized, b_resized), axis=2)\n",
    "    \n",
    "\n",
    "# Open the GeoTIFF image\n",
    "sentinel1_image_path = \"sentinel1_example.tif\"\n",
    "sentinel2_image_path = \"sentinel2_example.tif\"\n",
    "\n",
    "sentinel1 = rasterio.open(sentinel1_image_path)\n",
    "sentinel2 = rasterio.open(sentinel2_image_path)\n",
    "\n",
    "spatialAug1(sentinel1)\n",
    "spatialAug2(sentinel2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel 1 preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel 2 preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /home/charlie/.cache/torch/hub/v0.10.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/charlie/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 88.1MB/s]\n",
      "Using cache found in /home/charlie/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "resnet1  = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "resnet2  = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(x, y):\n",
    "    sim = torch.nn.CosineSimilarity()\n",
    "    l = np.empty(x.shape)\n",
    "    for i in range(len(l)):\n",
    "        lxyi = -torch.log(torch.exp(sim(x[i], y[i]))/(torch.sum(torch.exp(________)) + torch.sum(torch.exp(________))))\n",
    "        lyxi = -torch.log(torch.exp(sim(y[i], x[i]))/(torch.sum(torch.exp(________)) + torch.sum(torch.exp(________))))\n",
    "        l[i] = lxyi + lyxi\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
